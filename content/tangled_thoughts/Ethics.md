---
title: Ethics
date: 2024-10-22
tags: ["Philosophy"]
---


The subfield of Ethics in Philosophy concerns itself with the questions *What is morally right?* and *What is morally wrong?* The most well-known ethical systems are:

- **Deontology**, where we act in accordance with a set of rules (e.g., do not steal, do not kill).
- **Utilitarianism**, where we act in ways that try to maximize happiness and well-being for all involved.
- **Virtue ethics**, where we act in a way that embodies virtuous behavior (e.g., a virtuous person wouldn’t steal to enrich themselves but might steal if it meant feeding hungry children).

Let's consider the following scenario: we can kill one person to save five. How would these ethical systems respond?
A **deontologist**, if they follow a rule against killing, would probably disagree with the action. A **utilitarian** would most likely say yes, as maximizing the well-being of five people is better than that of one.  For a **virtue ethicist**, it would depend heavily on the situation and which virtues they believe are most important.

Now, let’s raise the stakes: we can kill one person to save five hundred. A **deontologist** and a **utilitarian** would most likely maintain their positions. If a **virtue ethicist** initially said no, it is foreseeable that they might now say yes.

What if we assume the worst possible case: we can kill one person to save the rest of humanity, or let the one person live and allow humanity to perish?
A **utilitarian**'s position remains the same. A **virtue ethicist** would likely also say yes, as it doesn't seem virtuous to doom all of humanity for the sake of a single person.
Even for a **deontologist**, despite the strict rules they typically follow, I don't believe they would refuse to break their rule in this scenario. One possible exception is if they adhere to **divine command theory**, which states that what is morally good is what is commanded by God.

It seems, then, that unless one’s morality comes from divine commands, all ethical systems ultimately collapse into **utilitarianism** if the stakes are raised high enough.


