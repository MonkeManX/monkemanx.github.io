---
title: 'Automatic Test Pattern Generation for Printed Neuromorphic Circuits'
date: 2025-12-14 08:00:00
tags: ["paper-summary", "Neuromorphic"]
---

**Paper Title:** Automatic Test Pattern Generation for Printed Neuromorphic Circuits

**Link to Paper:** https://ieeexplore.ieee.org/abstract/document/11049604

**Date:** 01 July 2025

**Paper Type:** Neuromorphics, Circuits, Fault Detection

**Short Abstract:**
In this paper, the authors propose using surrogate modeling of analog neuromorphic circuits combined with gradient-based methods for Automatic Test Pattern Generation (ATPG) to detect manufacturing faults in circuits.

## 1. Introduction

For an introduction to printed electronics, see [Towards Temporal Information Processing](paper-summary/towards_temporal_information_processing_printed_neuromorphic_circuits/) and [Highly-Bespoke Robust Printed Neuromorphic Circuits](/paper-summary/robust_printed_neuromorphic_chips/).

One major problem of printable electronics is their susceptibility to manufacturing faults. Unlike digital circuits, where standardized tests exist to detect such faults, no equivalent methods are available for analog circuits, which require customized approaches.

To address this issue and ensure the reliability of these circuits in the field, Automatic Test Pattern Generation (ATPG)—widely used for digital circuits—needs to be extended to analog neuromorphic circuits.

Recent advancements in machine learning, particularly in the area of built-in self-test (BIST) for analog devices, provide motivation to use gradient-based approaches for fault detection in analog circuits. These methods rely on neural network twins that replicate the behavior of the circuits. The approach maximizes the output discrepancy between faulty and fault-free systems, making it easier to distinguish between faulty and non-faulty circuits.

## 2. Background

### 2.1 Printed Analog Neuromorphic Circuits (pNCs)

The circuit consists of multiple components:

* **Resistor crossbar**: This implements programmable weights similar to those in artificial neural networks. The resistor values represent the network weights, and the weighted-sum operation performed by the crossbar is analogous to an artificial neuron.
* **Negative weights**: These are implemented using inverter-based circuits.
* **Activation function**: After the crossbar, an activation function is applied. A printable activation function is used to implement the hyperbolic tangent (`tanh`) function.

### 2.2 Defects in Additive Printing

In additive printing, we differentiate between:

* **Parametric variations**: Circuit components do not have exact nominal values but instead exhibit variability.
* **Catastrophic faults**: These include stuck-open or stuck-short faults, which can be simulated using resistors with very large or very small values (e.g., 100 MΩ and 1 Ω).

## 3. Methodology

To develop a test pattern generation framework capable of detecting faults in analog neuromorphic circuits, a gradient-based method is used. The goal is to maximize the output discrepancy between fault-free and faulty printable neuromorphic circuits.

Overall methodology:

1. Realistic fault modeling via circuit-level simulations
2. Fault abstraction to reduce test complexity
3. Gradient-based optimization to generate test inputs

### 3.1 Fault Modeling

The analog printed circuit is rebuilt in the SPICE simulation tool, and artificial faults are injected. SPICE simulations are then used to model faulty circuits and generate a faulty behavior dataset.

Faults can be injected into:

* Crossbar conductances
* Activation function circuits
* Inverter circuits

Only a single fault is injected at a time, as this simplifies analysis and because the probability of multiple simultaneous faults occurring in practice is low.

The faulty circuit behaviors are then translated into algorithmic transfer functions using curve fitting.

### 3.2 Fault Abstraction

Since exhaustive testing is not feasible, fault abstraction is used to reduce the fault set:

1. **Fault clustering**: Faults with similar transfer functions are clustered together using a distance-based learning approach. Each cluster is represented by a single fault.
2. **Untestable fault removal**: Faults that produce identical outputs to the fault-free circuit are deemed untestable and removed.

### 3.3 Gradient-Based Test Pattern Generation

For each abstracted fault, test inputs are generated by optimizing input patterns to maximize the output discrepancy between faulty and fault-free circuits.

The optimization objective is the Kullback–Leibler (KL) divergence between the softmax outputs of the fault-free and faulty pNC models.

Starting from multiple random initial inputs:

* The best candidate is refined using gradient descent with the Adam optimizer.
* Inputs are clipped to the range ([0, 1]) to respect physical voltage constraints.
* A fault is considered covered if the optimized input causes different class predictions for the fault-free and faulty models.

## 4. Evaluation

The gradient-based algorithm achieved over 90% fault coverage across multiple datasets, significantly outperforming random pattern testing. For example, fault coverage on the BreastCancWisc dataset reached 99.2%, compared to 49.2% with random patterns, albeit with a longer runtime (139 minutes).
