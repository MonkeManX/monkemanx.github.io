<!DOCTYPE html>
<html>
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
      
      <a id="top"></a>
      <meta charset="utf-8">
      <meta name="viewport" 
          content="width=device-width, initial-scale=1.0">
      <title>Notes from the Wired</title>
      
      <link rel="icon" href="http://localhost:1313/monke.png" sizes="64x64" type="image/png">
      
      
      <link rel="stylesheet" href="/styles/style.css">  

      <link rel="stylesheet" href="/css/syntax.css">
      <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    }
  };
</script>

  </head>
  <body><div class="nav-div">
  <nav>
        <a href="http://localhost:1313/" class="">Home</a>
        <a href="http://localhost:1313/articles/" class="">Articles</a>
        <a href="http://localhost:1313/paper-summary/" class="active">Paper-Summaries</a>
        <a href="http://localhost:1313/tags/" class="">Tags</a>
        <a href="http://localhost:1313/poetry/" class="">Writings</a>
        <a href="http://localhost:1313/tangled_thoughts/" class="">Tangled-Thoughts</a>
        <a href="http://localhost:1313/media/" class="">Media</a>
        <a href="http://localhost:1313/links/" class="">Links</a>
        <a href="http://localhost:1313/about/" class="">About</a>
  </nav>
</div>
<div id="content">
<div class="article-content"> 
  <h1> Self-Instruct: Aligning Language Models with Self-Generated Instructions </h1>
  <p class="pub-date">Published: February 2, 2024</p>
  
  <p><strong>Paper Title:</strong> Self-Instruct: Aligning Language Models with Self-Generated Instructions<br>
<strong>Link to Paper:</strong> <a href="https://arxiv.org/abs/2212.10560">https://arxiv.org/abs/2212.10560</a><br>
<strong>Date:</strong> 20. December 2022<br>
<strong>Paper Type:</strong> LLM, Alignment, Instruction<br>
<strong>Short Abstract:</strong><br>
Language Models (LLM) that are &ldquo;instruction tuned&rdquo; have demonstrated excellent raw performance and adherence to instructions. However, instruction tuning typically requires substantial amounts of human-labeled data. This paper introduces Self-Instruct, a technique for instruction tuning a LLM without relying extensively on human-labeled data.</p>
<h1 id="1-introduction">1. Introduction</h1>
<p>Recent advancements in Language Models (LLM) have significantly enhanced their performance, attributed to the use of pre-trained LLM and subsequent fine-tuning (as seen in the InstructGPT paper) on human-written instructional data (e.g., SUPER-NATURALINSTRUCTIONS). The challenge lies in the impracticality of collecting large datasets, often lacking diversity in the provided instructions.</p>
<p>In this paper, the authors propose SELF-INSTRUCT, a semi-automated process for instruction fine-tuning of LLM using instructions generated by the language model itself. The process begins with a small set of human-written tasks, which are then used iteratively to generate new task instances.</p>


<figure>
    <img style="display: block; margin-left: auto; margin-right: auto; width:80%" src="/attachments/Screenshot%20from%202024-02-02%2011-16-18.png">
</figure>


<p>In the Self-Instruct algorithm, the model is prompted to generate instructions for new tasks by leveraging the existing collection of instructions. Additionally, it is prompted to generate new instances (i.e., new examples) for a task. Subsequently, the generated content is filtered and added to the task pool.</p>
<p>To evaluate Self-Instruct, GPT-3 is employed and fine-tuned on the newly created data, followed by a comparison with other popular models. The authors also utilize ROUGE-L testing to assess the overlap between seed data and newly generated data, revealing only a small overlap.</p>
<h1 id="2-method">2. Method</h1>
<h2 id="21-instruction-data">2.1 Instruction Data</h2>
<p>Instruction data defines a task in natural language, each with an input-output instance associated. A model is expected to produce the output when given the instance and the input.</p>


<figure>
    <img style="display: block; margin-left: auto; margin-right: auto; width:50%" src="/attachments/Screenshot%20from%202024-02-02%2011-32-03.png">
</figure>


<h2 id="22-automatic-instruction-data-generation">2.2 Automatic Instruction Data Generation</h2>
<p>Their pipeline for generating new data consists of four steps:</p>
<ol>
<li>Instruction Generation</li>
<li>Identifying the type of the generated tasks</li>
<li>Generating instances for the tasks</li>
<li>Filtering low quality data</li>
</ol>
<p><strong>Instruction Generation</strong>
Initially, the task pool contains a small number of tasks, each with one instance. At each step, a number of tasks are sampled from this pool, including both human-written and generated tasks. The following prompt is used to generate new tasks:</p>


<figure>
    <img style="display: block; margin-left: auto; margin-right: auto; width:70%" src="/attachments/Screenshot%20from%202024-02-02%2011-35-58.png">
</figure>


<p><strong>Classification Task Identification</strong>
To classify the type of generated instruction, the LLM is prompted to determine whether a task is a classification task or not.</p>


<figure>
    <img style="display: block; margin-left: auto; margin-right: auto; width:60%" src="/attachments/Screenshot%20from%202024-02-02%2011-37-49.png">
</figure>


<p><strong>Instance Generation</strong>
Given the instruction and task type, the LLM is asked to generate new instances, which can be done via the input-first or output-first approach.</p>


<figure>
    <img style="display: block; margin-left: auto; margin-right: auto; width:60%" src="/attachments/Screenshot%20from%202024-02-02%2011-40-21.png">
</figure>


<p><strong>Filtering and Postprocessing</strong>
Filtering is performed using ROUGE-L, measuring the similarity between newly created text and existing content. If the content is too similar, it is discarded.</p>
<h2 id="23-finetuning-the-llm">2.3 Finetuning the LLM</h2>
<p>After generating the dataset using the Self-Instruct algorithm, the LLM can be fine-tuned on it. The model receives the input of the current instance and is asked to produce the corresponding output. Weights are adjusted based on the loss.</p>
<h1 id="3-produced-data">3. Produced Data</h1>
<p>This section provides an overview of the dataset produced using GPT-3 and self-instruct.</p>


<figure>
    <img style="display: block; margin-left: auto; margin-right: auto; width:50%" src="/attachments/Screenshot%20from%202024-02-02%2011-46-02.png">
</figure>


<p>For each generated instruction, the authors measure the ROUGE-L overlap with the initial seed instructions, indicating minimal overlap.</p>


<figure>
    <img style="display: block; margin-left: auto; margin-right: auto; width:50%" src="/attachments/Screenshot%20from%202024-02-02%2011-47-07.png">
</figure>


<p>To assess the quality of the data, samples are drawn from the dataset, and human evaluators are employed. Most generated tasks are found to be correct, and their instances are in the correct form. However, instances tend to have more noise than the generated tasks.</p>


<figure>
    <img style="display: block; margin-left: auto; margin-right: auto; width:50%" src="/attachments/Screenshot%20from%202024-02-02%2011-49-42.png">
</figure>


<h1 id="4-results">4. Results</h1>
<p>For evaluation, the authors compare their tuned GPT-3 model with Self-Instruct against InstructGPT.</p>


<figure>
    <img style="display: block; margin-left: auto; margin-right: auto; width:50%" src="/attachments/Screenshot%20from%202024-02-02%2011-53-03.png">
</figure>
<figure>
    <img style="display: block; margin-left: auto; margin-right: auto; width:60%" src="/attachments/Screenshot%20from%202024-02-02%2011-54-30.png">
</figure>


<h1 id="5-conclusion">5. Conclusion</h1>
<p>Self-Instruct facilitates significant performance gains for LLM even with limited initial data. Additionally, it proves to be nearly as effective as InstructGPT, which relies on a more extensive human-written dataset. Self-Instruct appears to be an accessible and cost-effective means to enhance the performance of any LLM, whether previously fine-tuned or not.</p>
 
</div>
<a href="#top" class="back-to-top-button">
  &#9650; 
</a>

    </div><div class="footer">
  Made with <a href="https://gohugo.io/">Hugo</a>, website licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>.
</div>
</body>
</html>
